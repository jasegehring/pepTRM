"""
MS2PIP-based synthetic peptide dataset for training.

Uses MS2PIP to generate realistic fragment ion predictions with proper
intensities, including doubly-charged ions (b++, y++) that our current
synthetic generator lacks.
"""

from dataclasses import dataclass
from typing import Iterator, Optional
import torch
from torch.utils.data import IterableDataset
import numpy as np

from ms2pip import predict_single

from ..constants import (
    STANDARD_VOCAB,
    AMINO_ACID_MASSES,
    WATER_MASS,
    PROTON_MASS,
    AA_TO_IDX,
    PAD_IDX,
)


@dataclass
class MS2PIPSample:
    """Sample generated by MS2PIP."""
    spectrum_masses: torch.Tensor  # (max_peaks,)
    spectrum_intensities: torch.Tensor  # (max_peaks,)
    spectrum_mask: torch.Tensor  # (max_peaks,) bool
    precursor_mass: torch.Tensor  # (1,)
    precursor_charge: torch.Tensor  # (1,)
    sequence: torch.Tensor  # (max_seq_len,) token IDs
    sequence_mask: torch.Tensor  # (max_seq_len,) bool


class MS2PIPSyntheticDataset(IterableDataset):
    """
    Synthetic peptide dataset using MS2PIP for spectrum prediction.

    MS2PIP (HCDch2 model) provides:
    - Realistic fragment intensities (trained on 21M real spectra)
    - Ion types: b, y (singly charged) + b2, y2 (doubly charged b++, y++)
    - Better representation of MS/MS physics than basic fragmentation rules
    - Covers ~85-90% of typical HCD fragment ion signal

    We still apply curriculum noise on top for progressive training.
    """

    def __init__(
        self,
        min_length: int = 7,
        max_length: int = 30,
        max_peaks: int = 100,
        max_seq_len: int = 35,
        charge_distribution: dict = {2: 0.7, 3: 0.3},
        # Curriculum noise parameters
        noise_peaks: int = 0,  # Legacy: single-tier noise (for backwards compat)
        noise_peaks_low: int = 0,  # Two-tier: low-intensity "grass" (0.0-0.1)
        noise_peaks_high: int = 0,  # Two-tier: high-intensity "spikes" (0.2-1.0)
        signal_suppression: float = 0.0,  # Prob of crushing real peak to <0.05
        peak_dropout: float = 0.0,
        mass_error_ppm: float = 0.0,
        intensity_variation: float = 0.0,
        # MS2PIP parameters
        ms2pip_model: str = "HCDch2",  # HCDch2 includes b, y, b++, y++ ions
        top_k_peaks: Optional[int] = None,  # Select top-k most intense peaks
    ):
        """
        Args:
            min_length: Minimum peptide length
            max_length: Maximum peptide length
            max_peaks: Maximum number of peaks in spectrum
            max_seq_len: Maximum sequence length (with padding)
            charge_distribution: Dict mapping charge -> probability
            noise_peaks: Number of noise peaks to add (curriculum)
            peak_dropout: Fraction of peaks to drop (curriculum)
            mass_error_ppm: Mass error in ppm (curriculum)
            intensity_variation: Intensity noise std (curriculum)
            ms2pip_model: Which MS2PIP model to use (default: HCDch2 for b, y, b++, y++)
            top_k_peaks: If set, only keep top-k most intense peaks
        """
        self.min_length = min_length
        self.max_length = max_length
        self.max_peaks = max_peaks
        self.max_seq_len = max_seq_len
        self.charge_distribution = charge_distribution

        # Curriculum noise
        self.noise_peaks = noise_peaks  # Legacy single-tier
        self.noise_peaks_low = noise_peaks_low  # Two-tier: grass
        self.noise_peaks_high = noise_peaks_high  # Two-tier: spikes
        self.signal_suppression = signal_suppression
        self.peak_dropout = peak_dropout
        self.mass_error_ppm = mass_error_ppm
        self.intensity_variation = intensity_variation
        self.clean_data_ratio = 1.0  # Start with 100% clean data

        # MS2PIP config
        self.ms2pip_model = ms2pip_model
        self.top_k_peaks = top_k_peaks

        # Validate model choice
        if ms2pip_model not in ['HCDch2', 'CIDch2', 'HCD2021', 'CID']:
            raise ValueError(
                f"Unsupported MS2PIP model: {ms2pip_model}. "
                "Recommended: 'HCDch2' for doubly-charged ion support."
            )

        # Use standard token vocabulary from constants.py
        self.amino_acids = list(STANDARD_VOCAB)
        self.token_to_idx = AA_TO_IDX  # Use main vocabulary indices
        self.idx_to_token = {v: k for k, v in self.token_to_idx.items()}
        self.vocab_size = len(self.token_to_idx)

        # Charge states
        self.charges = list(charge_distribution.keys())
        self.charge_probs = [charge_distribution[c] for c in self.charges]

    def set_difficulty(
        self,
        min_length: Optional[int] = None,
        max_length: Optional[int] = None,
        noise_peaks: Optional[int] = None,  # Legacy single-tier
        noise_peaks_low: Optional[int] = None,  # Two-tier: grass
        noise_peaks_high: Optional[int] = None,  # Two-tier: spikes
        signal_suppression: Optional[float] = None,
        peak_dropout: Optional[float] = None,
        mass_error_ppm: Optional[float] = None,
        intensity_variation: Optional[float] = None,
        clean_data_ratio: Optional[float] = None,
    ):
        """Update difficulty parameters for curriculum learning."""
        if min_length is not None:
            self.min_length = min_length
        if max_length is not None:
            self.max_length = max_length
        if noise_peaks is not None:
            self.noise_peaks = noise_peaks
        if noise_peaks_low is not None:
            self.noise_peaks_low = noise_peaks_low
        if noise_peaks_high is not None:
            self.noise_peaks_high = noise_peaks_high
        if signal_suppression is not None:
            self.signal_suppression = signal_suppression
        if peak_dropout is not None:
            self.peak_dropout = peak_dropout
        if mass_error_ppm is not None:
            self.mass_error_ppm = mass_error_ppm
        if intensity_variation is not None:
            self.intensity_variation = intensity_variation
        if clean_data_ratio is not None:
            self.clean_data_ratio = clean_data_ratio

    def _sample_peptide(self) -> str:
        """Sample a random peptide sequence."""
        length = np.random.randint(self.min_length, self.max_length + 1)
        sequence = ''.join(np.random.choice(self.amino_acids, size=length))
        return sequence

    def _sample_charge(self) -> int:
        """Sample a charge state."""
        return np.random.choice(self.charges, p=self.charge_probs)

    def _ms2pip_predict(self, peptide: str, charge: int):
        """
        Get MS2PIP prediction for peptide.

        Returns:
            masses: np.ndarray of m/z values
            intensities: np.ndarray of normalized intensities (0-1)
        """
        # Peptidoform format: "PEPTIDE/charge"
        peptidoform = f"{peptide}/{charge}"

        result = predict_single(peptidoform, model=self.ms2pip_model)

        # Extract predicted spectrum
        # ProcessingResult has:
        #   - theoretical_mz: dict[ion_type -> np.ndarray of mz values]
        #   - predicted_intensity: dict[ion_type -> np.ndarray of log intensities]

        all_masses = []
        all_intensities = []

        for ion_type in result.theoretical_mz.keys():
            mz_vals = result.theoretical_mz[ion_type]
            log_int_vals = result.predicted_intensity[ion_type]

            all_masses.append(mz_vals)
            all_intensities.append(log_int_vals)

        # Concatenate all ion types
        masses = np.concatenate(all_masses)
        log_intensities = np.concatenate(all_intensities)

        # Transform from log space to linear space
        intensities = np.exp(log_intensities)

        return masses, intensities

    def _apply_curriculum_noise(
        self,
        masses: np.ndarray,
        intensities: np.ndarray
    ) -> tuple[np.ndarray, np.ndarray]:
        """
        Apply curriculum noise to MS2PIP predictions.

        This simulates real-world instrument noise while keeping
        MS2PIP's realistic base intensities.

        Uses clean_data_ratio to mix clean and noisy samples:
        - clean_data_ratio=1.0: Always return clean data
        - clean_data_ratio=0.5: 50% clean, 50% noisy
        - clean_data_ratio=0.0: Always apply noise

        Two-tier noise model (sim-to-real bridge):
        - noise_peaks_low: "Grass" - chemical background (intensity 0.0-0.1)
        - noise_peaks_high: "Spikes" - contaminants (intensity 0.2-1.0)
        - signal_suppression: Crush real peaks to simulate ion suppression
        """
        # Check if we should apply noise to this sample
        if np.random.rand() < self.clean_data_ratio:
            # Return clean data (no noise)
            return masses, intensities

        # Apply noise to this sample
        # 1. Peak dropout (missing fragments)
        if self.peak_dropout > 0:
            keep_mask = np.random.rand(len(masses)) > self.peak_dropout
            masses = masses[keep_mask]
            intensities = intensities[keep_mask]

        # 2. Signal suppression - crush random real peaks to noise level
        # This decorrelates intensity from validity (real peaks can be weak)
        if self.signal_suppression > 0 and len(intensities) > 0:
            suppress_mask = np.random.rand(len(intensities)) < self.signal_suppression
            # Crush suppressed peaks to very low intensity (0.01-0.05)
            intensities[suppress_mask] = np.random.uniform(0.01, 0.05, suppress_mask.sum())

        # 3. Mass error
        if self.mass_error_ppm > 0:
            mass_errors = np.random.normal(0, self.mass_error_ppm / 1e6, len(masses))
            masses = masses * (1 + mass_errors)

        # 4. Intensity variation
        if self.intensity_variation > 0:
            intensity_noise = np.random.normal(0, self.intensity_variation, len(intensities))
            intensities = np.clip(intensities + intensity_noise, 0, 1)

        # 5. Add noise peaks (legacy single-tier)
        if self.noise_peaks > 0:
            max_mass = masses.max() if len(masses) > 0 else 2000.0
            noise_masses = np.random.uniform(50, max_mass, self.noise_peaks)
            noise_intensities = np.random.exponential(0.1, self.noise_peaks)
            noise_intensities = np.clip(noise_intensities, 0, 0.5)

            masses = np.concatenate([masses, noise_masses])
            intensities = np.concatenate([intensities, noise_intensities])

        # 6. Two-tier noise: "Grass" (low-intensity background)
        if self.noise_peaks_low > 0:
            max_mass = masses.max() if len(masses) > 0 else 2000.0
            grass_masses = np.random.uniform(50, max_mass, self.noise_peaks_low)
            # Low intensity: uniform 0.0-0.1 (chemical background noise)
            grass_intensities = np.random.uniform(0.0, 0.1, self.noise_peaks_low)

            masses = np.concatenate([masses, grass_masses])
            intensities = np.concatenate([intensities, grass_intensities])

        # 7. Two-tier noise: "Spikes" (high-intensity contaminants)
        # These kill the "big = real" bias by adding decoy bright peaks
        if self.noise_peaks_high > 0:
            max_mass = masses.max() if len(masses) > 0 else 2000.0
            spike_masses = np.random.uniform(50, max_mass, self.noise_peaks_high)
            # High intensity: uniform 0.2-1.0 (contaminants, co-eluting peptides)
            spike_intensities = np.random.uniform(0.2, 1.0, self.noise_peaks_high)

            masses = np.concatenate([masses, spike_masses])
            intensities = np.concatenate([intensities, spike_intensities])

        return masses, intensities

    def _generate_sample(self) -> MS2PIPSample:
        """Generate a single training sample using MS2PIP."""
        # 1. Sample peptide and charge
        peptide = self._sample_peptide()
        charge = self._sample_charge()

        # 2. Get MS2PIP predictions (returns numpy arrays)
        masses, intensities = self._ms2pip_predict(peptide, charge)

        # 3. HCDch2 model provides: b, y (singly charged) and b2, y2 (doubly charged)

        # 4. Normalize intensities
        if intensities.max() > 0:
            intensities = intensities / intensities.max()

        # 5. Select top-k peaks if specified
        if self.top_k_peaks and len(masses) > self.top_k_peaks:
            top_indices = np.argsort(intensities)[-self.top_k_peaks:]
            masses = masses[top_indices]
            intensities = intensities[top_indices]

        # 6. Apply curriculum noise
        masses, intensities = self._apply_curriculum_noise(masses, intensities)

        # 7. Sort by mass
        sort_indices = np.argsort(masses)
        masses = masses[sort_indices]
        intensities = intensities[sort_indices]

        # 8. Truncate or pad to max_peaks
        num_peaks = min(len(masses), self.max_peaks)
        peak_mask = np.zeros(self.max_peaks, dtype=bool)
        peak_mask[:num_peaks] = True

        spectrum_masses = np.zeros(self.max_peaks, dtype=np.float32)
        spectrum_intensities = np.zeros(self.max_peaks, dtype=np.float32)
        spectrum_masses[:num_peaks] = masses[:num_peaks]
        spectrum_intensities[:num_peaks] = intensities[:num_peaks]

        # 9. Calculate precursor mass
        precursor_mass = sum(AMINO_ACID_MASSES[aa] for aa in peptide) + WATER_MASS

        # 10. Encode sequence as token IDs
        seq_tokens = [self.token_to_idx[aa] for aa in peptide]
        seq_len = len(seq_tokens)

        sequence = np.zeros(self.max_seq_len, dtype=np.int64)
        sequence_mask = np.zeros(self.max_seq_len, dtype=bool)
        sequence[:seq_len] = seq_tokens
        sequence_mask[:seq_len] = True

        return MS2PIPSample(
            spectrum_masses=torch.from_numpy(spectrum_masses),
            spectrum_intensities=torch.from_numpy(spectrum_intensities),
            spectrum_mask=torch.from_numpy(peak_mask),
            precursor_mass=torch.tensor(precursor_mass, dtype=torch.float32),
            precursor_charge=torch.tensor(charge, dtype=torch.int64),
            sequence=torch.from_numpy(sequence),
            sequence_mask=torch.from_numpy(sequence_mask),
        )

    def __iter__(self) -> Iterator[MS2PIPSample]:
        """Infinite iterator over synthetic samples."""
        while True:
            yield self._generate_sample()


def create_ms2pip_dataloader(
    batch_size: int,
    num_workers: int = 4,
    **dataset_kwargs
):
    """Create DataLoader for MS2PIP synthetic dataset."""
    from torch.utils.data import DataLoader

    dataset = MS2PIPSyntheticDataset(**dataset_kwargs)

    # Custom collate function
    def collate_fn(batch):
        return {
            'peak_masses': torch.stack([s.spectrum_masses for s in batch]),
            'peak_intensities': torch.stack([s.spectrum_intensities for s in batch]),
            'peak_mask': torch.stack([s.spectrum_mask for s in batch]),
            'precursor_mass': torch.stack([s.precursor_mass for s in batch]),
            'precursor_charge': torch.stack([s.precursor_charge for s in batch]),
            'sequence': torch.stack([s.sequence for s in batch]),
            'sequence_mask': torch.stack([s.sequence_mask for s in batch]),
        }

    return DataLoader(
        dataset,
        batch_size=batch_size,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=True,
    )
